# API-Watch üîç

**API Debugging & Monitoring Toolkit for Customer Integrations (FDE Utility)**

> **Watch, debug, and monitor REST APIs ‚Äî Built for Forward Deployed Engineers**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/yourusername/api-watch.svg?style=social)](https://github.com/yourusername/api-watch/stargazers)
[![Last commit](https://img.shields.io/github/last-commit/yourusername/api-watch.svg)](https://github.com/yourusername/api-watch/commits/main)

**API-Watch** is a production-ready CLI toolkit that helps Forward Deployed Engineers, Customer Success teams, and API integrators test, debug, and validate customer API integrations with intelligent retry logic, automated error diagnosis, and beautiful reporting.

---

## üåü Features

### Core Capabilities
‚úÖ **API Request Runner** - Supports GET, POST, PUT, DELETE with full configuration  
‚úÖ **Smart Authentication** - Bearer Token, API Key, and Basic Auth support  
‚úÖ **Intelligent Retry Logic** - Exponential backoff for 429 rate limits and 5xx server errors  
‚úÖ **Auto-Diagnosis Engine** - Detects and explains common API failures with troubleshooting steps  
‚úÖ **Detailed Logging** - Captures request/response details, latency, payload sizes, and errors  
‚úÖ **Report Generation** - Beautiful HTML dashboards and machine-readable JSON reports  
‚úÖ **YAML Test Suites** - Define and run complete onboarding validation workflows  
‚úÖ **Webhook Test Server** - Local FastAPI server to receive and log webhook payloads  

  
---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     API-Watch Architecture                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CLI Entry  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   YAML Test Suite Parser     ‚îÇ
‚îÇ  (main.py)   ‚îÇ         ‚îÇ  (Loads customer test cases) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                                       ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   Request Runner Engine     ‚îÇ
                         ‚îÇ  - Auth Handler             ‚îÇ
                         ‚îÇ  - Retry Logic              ‚îÇ
                         ‚îÇ  - Timeout Management       ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚ñº                   ‚ñº                   ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ Auto-Diagnosis ‚îÇ  ‚îÇ  Logger        ‚îÇ  ‚îÇ Report Builder ‚îÇ
          ‚îÇ Engine         ‚îÇ  ‚îÇ  (JSON/CSV)    ‚îÇ  ‚îÇ (HTML/JSON)    ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ                   ‚îÇ                   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                       ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ   Output Artifacts          ‚îÇ
                         ‚îÇ  ‚Ä¢ logs/requests.log        ‚îÇ
                         ‚îÇ  ‚Ä¢ reports/report.html      ‚îÇ
                         ‚îÇ  ‚Ä¢ reports/report.json      ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Webhook Test Server (Optional)                 ‚îÇ
‚îÇ  FastAPI server on localhost:8080 to test webhooks         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Components:**
- **CLI Entry**: Command-line interface for running tests
- **Test Suite Parser**: Reads and validates YAML test configurations
- **Request Runner**: Executes HTTP requests with auth, retries, and timeouts
- **Auto-Diagnosis**: Analyzes failures and provides troubleshooting steps
- **Report Builder**: Generates shareable HTML/JSON reports
- **Webhook Server**: Local endpoint for webhook development and testing

---

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/api-debug-toolkit.git
cd api-debug-toolkit

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Setup Environment

```bash
# Copy sample environment file
cp examples/env.sample .env

# Edit .env with your API credentials
# Add your API_TOKEN, API_KEY, BASE_URL, etc.
```

---

## ÔøΩ Example Output

### Terminal Output

![Terminal Output](docs/screenshots/terminal-output.png)
*Live terminal output showing test execution with color-coded status indicators*
> **Note:** Screenshot placeholders - Run `python src/main.py suite --file examples/customer_onboarding_suite.yaml` and capture your terminal to add actual screenshots. See [docs/screenshots/PLACEHOLDER.md](docs/screenshots/PLACEHOLDER.md) for instructions.
### HTML Report

![HTML Report](docs/screenshots/html-report.png)
*Beautiful HTML dashboard with test results, diagnostics, and troubleshooting steps*

**Key Report Features:**
- ‚úÖ Pass/Fail status for each test
- ‚è±Ô∏è Response time metrics
- üìä Success rate summary
- üîç Automatic error diagnosis
- üí° Actionable troubleshooting suggestions
- üìã Complete request/response details

---

## üß™ How to Run Smoke Tests

### 1. Single API Request Test

Test a single endpoint quickly:

```bash
# Test a GET endpoint
python src/main.py request --method GET --url https://api.example.com/health

# Test with authentication
python src/main.py request \
  --method GET \
  --url https://api.plivo.com/v1/Account/MAXXXXXX/ \
  --bearer YOUR_AUTH_TOKEN
```

**Output:**
```
‚úì Request successful (200 OK)
‚è±Ô∏è  Response time: 245ms
üì¶ Response size: 1.2KB
```

### 2. Run Complete Test Suite

Run customer onboarding validation:

```bash
# Run customer onboarding test suite
python src/main.py suite --file examples/customer_onboarding_suite.yaml

# Run with verbose logging
python src/main.py suite --file examples/customer_onboarding_suite.yaml --verbose
```

**What it does:**
1. Reads YAML test configuration
2. Executes all tests sequentially
3. Automatically retries failures
4. Generates HTML + JSON reports
5. Saves detailed logs

**Generated Reports:**
- `reports/report_2026-01-19_14-30-45.html` - Visual dashboard
- `reports/report_2026-01-19_14-30-45.json` - Machine-readable data
- `logs/2026-01-19_14-30-45.log` - Detailed execution logs

### 3. Customer Onboarding Test Suite

Use the pre-built customer onboarding suite:

```bash
python src/main.py suite --file examples/customer_onboarding_suite.yaml
```

This suite validates:
- ‚úÖ Account authentication
- ‚úÖ Profile retrieval
- ‚úÖ Resource creation (tickets, messages, etc.)
- ‚úÖ Webhook configuration
- ‚úÖ Rate limit handling
- ‚úÖ Error scenarios

---

## üîó How Webhook Testing Works

### Why Test Webhooks Locally?

**Problem:** Testing webhooks in production is risky and slow
- Can't test without deploying to a public server
- ngrok/localtunnel require extra setup
- Hard to debug payload issues

**Solution:** API-Watch includes a local webhook server

### Start the Webhook Server

```bash
# Start webhook server on default port (8080)
python src/webhook_server.py

# Use custom port
python src/webhook_server.py --port 9000
```

**Server Features:**
- Receives POST requests on `/webhook`
- Logs all incoming payloads
- Returns 200 OK automatically
- Saves payloads to `logs/webhooks/`

### Test Webhook Integration

1. **Start the server:**
   ```bash
   python src/webhook_server.py --port 8080
   ```

2. **Configure your API to send webhooks to:**
   ```
   http://localhost:8080/webhook
   ```

3. **View logged payloads:**
   ```bash
   cat logs/webhooks/webhook_2026-01-19_14-30-45.json
   ```

**Example logged payload:**
```json
{
  "timestamp": "2026-01-19T14:30:45Z",
  "headers": {
    "Content-Type": "application/json",
    "X-Webhook-Signature": "sha256=..."
  },
  "body": {
    "event": "message.delivered",
    "message_uuid": "123-456-789",
    "status": "delivered"
  }
}
```

### Use Cases
- ‚úÖ Test webhook payloads before production
- ‚úÖ Debug webhook signature validation
- ‚úÖ Validate JSON structure
- ‚úÖ Test rate limiting and retry logic

---

## üõ†Ô∏è Troubleshooting

### Common Issues and Solutions

#### ‚ùå **401 Unauthorized**
**Diagnosis:** Invalid or missing authentication token

**Solutions:**
1. Check your `.env` file has the correct `API_TOKEN`
2. Verify token hasn't expired
3. Ensure token has proper format (Bearer vs API Key)

```bash
# Verify token
echo $API_TOKEN

# Test with explicit token
python src/main.py request --url YOUR_URL --bearer YOUR_TOKEN
```

#### ‚ùå **403 Forbidden**
**Diagnosis:** Valid auth but insufficient permissions

**Solutions:**
1. Check API key has required scopes/permissions
2. Verify account is not suspended
3. Contact API provider to verify access level

#### ‚ùå **429 Rate Limited**
**Diagnosis:** Too many requests

**Solutions:**
- API-Watch automatically retries with exponential backoff
- Adjust retry settings in your test suite:
  ```yaml
  defaults:
    retries: 5
    timeout_seconds: 10
  ```

#### ‚ùå **Connection Timeout**
**Diagnosis:** Network latency or slow endpoint

**Solutions:**
1. Check internet connection
2. Increase timeout in test suite:
   ```yaml
   defaults:
     timeout_seconds: 30
   ```
3. Verify endpoint URL is correct

#### ‚ùå **SSL Certificate Error**
**Diagnosis:** Invalid or self-signed certificate

**Solutions:**
```bash
# For development only - disable SSL verification
python src/main.py request --url YOUR_URL --no-verify-ssl
```

### Debug Mode

Run with verbose logging:

```bash
# Enable debug output
python src/main.py suite --file examples/test_suite.yaml --verbose

# Check detailed logs
cat logs/LATEST.log
```

---

## üìã Test Suite Format

Create a YAML file for your smoke tests:

```yaml
name: "Customer Onboarding Smoke Tests"
base_url: "https://api.example.com"

defaults:
  headers:
    Content-Type: "application/json"
  timeout_seconds: 8
  retries: 3

auth:
  type: bearer
  token_env: API_TOKEN

tests:
  - id: health_check
    method: GET
    path: /health

  - id: get_profile
    method: GET
    path: /v1/profile

  - id: create_ticket
    method: POST
    path: /v1/tickets
    body:
      title: "Test ticket"
      priority: "high"
```

---

## üîç Features Deep Dive

### Auto-Diagnosis Engine

The toolkit automatically diagnoses common API failures:

| Status Code | Diagnosis | Actionable Suggestion |
|-------------|-----------|----------------------|
| **401** | Token missing/expired | Check `.env` file and verify `API_TOKEN` is valid |
| **403** | Insufficient permissions | Verify API key has required scopes/permissions |
| **429** | Rate limit exceeded | Automatic retry with backoff (wait 1s ‚Üí 2s ‚Üí 4s ‚Üí 8s) |
| **5xx** | Server error | Auto-retry enabled; contact API provider if persists |
| **Timeout** | Network/endpoint latency | Check network connection, increase `timeout_seconds` |
| **Connection** | DNS/network failure | Verify endpoint URL and internet connection |

**Example Diagnostic Output:**
```
‚ùå Test Failed: get_user_profile
Status: 401 Unauthorized
Diagnosis: Authentication token is missing or invalid
Suggestion: Check your .env file and ensure API_TOKEN is set correctly
```

### Retry Logic

- **Smart Retry**: Automatically retries `429` (rate limit) and `5xx` (server errors)
- **Exponential Backoff**: 1s ‚Üí 2s ‚Üí 4s ‚Üí 8s between retries
- **Configurable**: Set `retries: 5` in your test suite YAML
- **Selective**: Doesn't retry on 4xx client errors (except 429)

**Retry Flow:**
```
Request ‚Üí 429 Rate Limited ‚Üí Wait 1s ‚Üí Retry
       ‚Üí 503 Server Error ‚Üí Wait 2s ‚Üí Retry
       ‚Üí 500 Server Error ‚Üí Wait 4s ‚Üí Retry
       ‚Üí 200 Success ‚úì
```

### Logging

All requests are comprehensively logged:

**Captured Data:**
- üïê Timestamp
- üîó Method and URL
- üìù Request headers and body
- ‚úÖ Response status code
- ‚è±Ô∏è Response time (latency)
- üì¶ Response size
- ‚ùå Error details and stack traces

**Log Location:** `logs/<timestamp>.log`

**Example Log Entry:**
```log
[2026-01-19 14:30:45] INFO - Request: GET https://api.plivo.com/v1/Account/
[2026-01-19 14:30:45] INFO - Auth: Bearer Token
[2026-01-19 14:30:45] INFO - Response: 200 OK (245ms, 1.2KB)
[2026-01-19 14:30:45] INFO - Success ‚úì
```

### Reports

Generated after each test suite run:

**HTML Report** (`reports/report_<timestamp>.html`)
- Visual dashboard with color-coded results
- Test summary with pass/fail counts
- Detailed diagnostics for each test
- Troubleshooting suggestions
- Charts and metrics

**JSON Report** (`reports/report_<timestamp>.json`)
- Machine-readable format
- Structured test results
- Integration with CI/CD pipelines
- Easy parsing for automation

**Report Contents:**
```json
{
  "summary": {
    "total_tests": 10,
    "passed": 8,
    "failed": 2,
    "success_rate": 80,
    "avg_response_time": 245
  },
  "tests": [...],
  "diagnostics": [...]
}
```

---

## üõ†Ô∏è Tech Stack

**Core Technologies:**
- **Python 3.11+** - Modern Python with type hints
- **requests** - Industry-standard HTTP client
- **pyyaml** - YAML parsing for test suite configuration
- **rich** - Beautiful terminal UI with colors and progress bars
- **jinja2** - HTML report templating
- **fastapi** - Async webhook server framework
- **uvicorn** - ASGI server for FastAPI
- **pytest** - Testing framework

**Why These Choices:**
- **Lightweight**: Minimal dependencies, fast installation
- **Reliable**: Battle-tested libraries used in production
- **Extensible**: Easy to add new features and integrations
- **Cross-platform**: Works on Windows, macOS, and Linux

---

## üìÅ Project Structure

```
api-watch/
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ main.py              # CLI entry point with argparse
‚îÇ  ‚îú‚îÄ runner.py            # API request executor with retry logic
‚îÇ  ‚îú‚îÄ auth.py              # Authentication handlers (Bearer, API Key, Basic)
‚îÇ  ‚îú‚îÄ retry.py             # Retry logic with exponential backoff
‚îÇ  ‚îú‚îÄ diagnose.py          # Error diagnosis engine
‚îÇ  ‚îú‚îÄ report.py            # HTML/JSON report generation
‚îÇ  ‚îú‚îÄ utils.py             # Utility functions (logging, validation)
‚îÇ  ‚îî‚îÄ webhook_server.py    # FastAPI webhook receiver
‚îú‚îÄ tests/
‚îÇ  ‚îú‚îÄ test_runner.py       # Unit tests for request runner
‚îÇ  ‚îú‚îÄ test_auth.py         # Authentication tests
‚îÇ  ‚îî‚îÄ test_diagnose.py     # Diagnosis engine tests
‚îú‚îÄ examples/
‚îÇ  ‚îú‚îÄ test_suite.yaml              # Sample test suite
‚îÇ  ‚îú‚îÄ customer_onboarding_suite.yaml  # FDE customer onboarding tests
‚îÇ  ‚îú‚îÄ env.sample                   # Environment variables template
‚îÇ  ‚îî‚îÄ sample_payload.json          # Sample request payload
‚îú‚îÄ reports/                # Generated HTML/JSON reports
‚îú‚îÄ logs/                   # Request/response logs
‚îú‚îÄ docs/
‚îÇ  ‚îú‚îÄ screenshots/         # Documentation screenshots
‚îÇ  ‚îú‚îÄ DEPLOYMENT.md        # Detailed deployment guide
‚îÇ  ‚îî‚îÄ QUICK_DEPLOY.md      # 10-minute deployment checklist
‚îú‚îÄ README.md               # This file
‚îú‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ .env.example            # Environment template
‚îú‚îÄ .gitignore
‚îî‚îÄ LICENSE
```

---

## üöÄ Deployment (Production-Ready)

API-Watch consists of two components:
1. **CLI Tool** - Runs locally on your laptop/server
2. **Webhook Server** - FastAPI server that can be deployed publicly

### Deploy Webhook Server on Render (Free)

**Why Deploy?**
- Get a public HTTPS endpoint for webhook testing
- Test customer webhook integrations remotely
- Share webhook testing capabilities with your team

**Step 1: Prepare Repository**

The repository already includes `render.yaml` configuration:

```yaml
services:
  - type: web
    name: api-watch-webhook
    env: python
    plan: free
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn src.webhook_server:app --host 0.0.0.0 --port 10000
```

**Step 2: Deploy to Render**

1. **Sign up** at [render.com](https://render.com)
2. **Connect GitHub** - Link your API-Watch repository
3. **Create Web Service**:
   - Select "New Web Service"
   - Choose your API-Watch repository
   - Render will auto-detect `render.yaml`
4. **Deploy** - Click "Create Web Service"

**Step 3: Get Your Webhook URL**

After deployment (takes 2-3 minutes), you'll receive:
```
https://api-watch-webhook.onrender.com
```

Your webhook endpoint:
```
https://api-watch-webhook.onrender.com/webhook
```

**Step 4: Test Your Deployed Webhook**

```bash
# Test from anywhere
curl -X POST https://api-watch-webhook.onrender.com/webhook \
  -H "Content-Type: application/json" \
  -d '{"event": "test", "status": "success"}'
```

**Resume Impact:**
> "Deployed production webhook testing server on Render with public HTTPS endpoint for customer integration validation."

---

### Deploy Reports to Cloudflare Pages (Free)

Host your generated HTML reports publicly for easy sharing.

**Step 1: Generate Sample Report**

```bash
# Run test suite to generate report
python src/main.py suite --file examples/customer_onboarding_suite.yaml

# Copy latest report to public folder
cp reports/report_latest.html public/report.html
```

**Step 2: Deploy to Cloudflare Pages**

1. Sign up at [pages.cloudflare.com](https://pages.cloudflare.com)
2. Connect your GitHub repository
3. Configure build:
   - **Build command**: (leave empty)
   - **Build output directory**: `public`
4. Deploy

**Your Reports URL:**
```
https://api-watch.pages.dev
```

**Benefits:**
- Share test reports with customers instantly
- Professional-looking hosted documentation
- Free CDN with HTTPS
- Zero configuration required

---

### Alternative Deployment Options

**Railway** (Easy alternative to Render)
```bash
# Install Railway CLI
npm install -g @railway/cli

# Deploy
railway login
railway init
railway up
```

**Fly.io** (Advanced - Docker-based)
```bash
# Install flyctl
# Create Dockerfile (if needed)
fly launch
fly deploy
```

**Docker Deployment**
```bash
# Build image
docker build -t api-watch-webhook .

# Run locally
docker run -p 8080:8080 api-watch-webhook

# Deploy to any cloud provider supporting Docker
```

---

## ü§ù Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.


---

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.


